{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      0      1       2       3        4        5       6        7       8   \\\n0  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710  0.2419   \n1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017  0.1812   \n2  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790  0.2069   \n3  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520  0.2597   \n4  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430  0.1809   \n\n        9   ...     20     21      22      23      24      25      26      27  \\\n0  0.07871  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n1  0.05667  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n2  0.05999  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n3  0.09744  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n4  0.05883  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n\n       28       29  \n0  0.4601  0.11890  \n1  0.2750  0.08902  \n2  0.3613  0.08758  \n3  0.6638  0.17300  \n4  0.2364  0.07678  \n\n[5 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>25</th>\n      <th>26</th>\n      <th>27</th>\n      <th>28</th>\n      <th>29</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>0.2419</td>\n      <td>0.07871</td>\n      <td>...</td>\n      <td>25.38</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>0.1812</td>\n      <td>0.05667</td>\n      <td>...</td>\n      <td>24.99</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>0.2069</td>\n      <td>0.05999</td>\n      <td>...</td>\n      <td>23.57</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>0.2597</td>\n      <td>0.09744</td>\n      <td>...</td>\n      <td>14.91</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>0.1809</td>\n      <td>0.05883</td>\n      <td>...</td>\n      <td>22.54</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "(569,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_targets(targets):\n",
    "    new_targets = copy.copy(targets)\n",
    "    new_targets[np.where(targets > 0)] = 1\n",
    "    new_targets[np.where(targets <= 0)] = -1\n",
    "    return new_targets.reshape((new_targets.shape[0],1))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y = correct_targets(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Problem definition\n",
    "### 3.1. Ogólnie\n",
    "Zadanie polega na znalezieniu funkcji $$ f(x)={w^{T}x+b}$$, która tworzy hiperpłaszczyznę zapewniającą klasyfikację (dopuszczającą pomyłki) z użyciem maszyny wektorów nośnych SVM. Otrzymana funkcja powinna zapewniać jak najmniejszą liczbę pomyłek przy klasyfikowaniu elementów zbioru BREAST CANCER do odpowiedniej klasy.\n",
    "\n",
    "Klasyfikacja odbywa się poprzez zwrócenie dla danego zestawu cech $x$ grupy $y(x) = -1 \\lor y(x) = 1$, do której należy za pomocą funkcji:\n",
    "\n",
    "$$\n",
    "y(x) =\n",
    "{\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "-1 & \\textrm{, $f(x) \\leq 0$}\\\\\n",
    "1 & \\textrm{, $f(x) > 0$}\n",
    "\\end{array}\n",
    "\\right\n",
    "}\n",
    "$$\n",
    "\n",
    "\n",
    "Aby otrzymać funkcję $f(x)$ należy znaleźć parametry $w$ i $b$, które minimalizują funkcję straty:\n",
    "$$ J(w,b)=\\Sigma_i(max(1-f(x_i)y_i, 0)) + \\lambda*||w||^2 $$\n",
    "\n",
    "Aby zoptymalizować owe parametry, zastosowana zostanie metoda gradientu prostego, w tym celu potrzebny będzie gradient funkcji $J(w,b)$:\n",
    "$$\n",
    "\\nabla J =\n",
    "\\begin{bmatrix}\n",
    "    \\partial J \\over \\partial w_1 \\\\\n",
    "    \\vdots \\\\\n",
    "    \\partial J \\over \\partial w_n \\\\\n",
    "    \\partial J \\over \\partial b \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Natomiast pochodne cząstkowe te prezentują się następująco:\n",
    "$$\n",
    "{\\partial J \\over \\partial w_i}=\n",
    "{\\lambda*2*w_i} + \\Sigma_k(1 \\cdot\n",
    "{\\left\\{ \\begin{array}{ll}\n",
    "0 & \\textrm{, $ 1-f(x_k)y_k \\leq 0$ }\\\\\n",
    "-y_k \\cdot x_{k[i]} & \\textrm{, $ 1-f(x_k)y_k > 0$}\n",
    "\\end{array}\\right })\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "{\\partial J \\over \\partial b}=\n",
    "\\Sigma_k (1 * {\n",
    "\\left\\{ \\begin{array}{ll}\n",
    "0 & \\textrm{, $ 1-f(x_k) \\cdot y_k \\leq 0$ }\\\\\n",
    "y_k & \\textrm{, $ 1-f(x_k) \\cdot y_k > 0$}\n",
    "\\end{array}\\right\n",
    "}\n",
    ")\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Functions to train:\n",
    "+ funkcja **f(x)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, params):\n",
    "    b = params[-1,:]\n",
    "    W = params[:-1,:]\n",
    "    return np.dot(x,W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ gradient **J(w, b)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def grad_j(params, set_xs, set_ys, lambd, function_f):\n",
    "    # numpy array of partial derivatives\n",
    "    b = params[-1,:]\n",
    "    W = params[:-1,:]\n",
    "    partials = np.zeros_like(params, dtype=np.float64)\n",
    "\n",
    "    # counting gradients for w1, w2, ..., wn\n",
    "    distances = 1 - np.multiply(set_ys, function_f(set_xs, params))\n",
    "    distances = distances.reshape((distances.shape[0],))\n",
    "    # sum = 2 * λ * wi + (0 or iyx) over all samples\n",
    "    x_w_part = np.zeros_like(set_xs)\n",
    "    x_w_part[np.where(distances>0)] -= (set_ys*set_xs)[np.where(distances>0)]\n",
    "    partials[:-1,:] = 2*lambd*W + np.sum(x_w_part,axis=0).reshape(partials[:-1,:].shape)\n",
    "\n",
    "    # counting gradient for b\n",
    "    x_b_part = np.zeros_like(set_ys, dtype=np.float64)\n",
    "    x_b_part[np.where(distances>0)] += set_ys[np.where(distances>0)]\n",
    "    partials[-1,:] = np.sum(x_b_part, axis=0)\n",
    "\n",
    "    return partials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ algorytm realizujący metodę gradientu prostego:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(function_f, gradient_f, params, beta, set_xs, set_ys, lambd, max_steps=10000, min_epsilon = 1e-20):\n",
    "    new_param = params\n",
    "    act_step = 0\n",
    "    while 1:\n",
    "        act_gradient = gradient_f(new_param, set_xs, set_ys, lambd, function_f)\n",
    "        if np.linalg.norm(act_gradient) < min_epsilon or act_step > max_steps:\n",
    "            return new_param\n",
    "        new_param = new_param - beta * act_gradient\n",
    "        act_step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Functions to evaluate:\n",
    "+ funkcja **y(x)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_y(x, function_f, params):\n",
    "    return 2*(function_f(x, params) > 0) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train & test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ dodatkowo zostaną zdefiniowane funkcje: trenujące model (**train_model()**) oraz wykonujące walidacje dla hiperparametru lambda(**validate_model()**)\n",
    "+ a także zostanie zdefiniowany zbiór możliwych lambd **lambdas = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5]**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5]\n",
    "\n",
    "def train_model(model0, training_set_x, training_set_y, param_lambda):\n",
    "    return gradient_descent(f, grad_j, model0, 0.01, training_set_x, training_set_y, param_lambda)\n",
    "\n",
    "def validate_model(training_set_x, training_set_y, validating_set_x, validating_set_y):\n",
    "    best_model = None\n",
    "    best_lambda = None\n",
    "    best_score = - math.inf\n",
    "\n",
    "    for param_lambda in lambdas:\n",
    "        model0 = np.zeros(shape=(training_set_x.shape[1] + 1,1), dtype=np.float64)\n",
    "        current_model = train_model(model0, training_set_x, training_set_y, param_lambda)\n",
    "        # results_validating = np.zeros(len(validating_set_y), dtype='int')\n",
    "        results_validating = classify_y(validating_set_x, f, current_model)\n",
    "        n_of_successes = 0\n",
    "        for x, y in zip(results_validating, validating_set_y):\n",
    "            if x == y:\n",
    "                n_of_successes += 1\n",
    "        print(f\"Validating model with lambda: {param_lambda} gave score: {n_of_successes / len(results_validating)}\")\n",
    "        # as long as new score is not worse than actual best, lambda should be maximized\n",
    "        if (n_of_successes / len(results_validating) >= best_score):      \n",
    "            best_score = n_of_successes / len(results_validating)\n",
    "            best_lambda = param_lambda\n",
    "            best_model = current_model\n",
    "    print(f\"Best lambda for this validation equals: {best_lambda} with score: {best_score}\")\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating model with lambda: 0.0001 gave score: 0.9418604651162791\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [13]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mvalidate_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [12]\u001B[0m, in \u001B[0;36mvalidate_model\u001B[1;34m(training_set_x, training_set_y, validating_set_x, validating_set_y)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m param_lambda \u001B[38;5;129;01min\u001B[39;00m lambdas:\n\u001B[0;32m     12\u001B[0m     model0 \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros(shape\u001B[38;5;241m=\u001B[39m(training_set_x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m), dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat64)\n\u001B[1;32m---> 13\u001B[0m     current_model \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining_set_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining_set_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparam_lambda\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;66;03m# results_validating = np.zeros(len(validating_set_y), dtype='int')\u001B[39;00m\n\u001B[0;32m     15\u001B[0m     results_validating \u001B[38;5;241m=\u001B[39m classify_y(validating_set_x, f, current_model)\n",
      "Input \u001B[1;32mIn [12]\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model0, training_set_x, training_set_y, param_lambda)\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_model\u001B[39m(model0, training_set_x, training_set_y, param_lambda):\n\u001B[1;32m----> 4\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgradient_descent\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_j\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining_set_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining_set_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparam_lambda\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [10]\u001B[0m, in \u001B[0;36mgradient_descent\u001B[1;34m(function_f, gradient_f, params, beta, set_xs, set_ys, lambd, max_steps, min_epsilon)\u001B[0m\n\u001B[0;32m      3\u001B[0m act_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m----> 5\u001B[0m     act_gradient \u001B[38;5;241m=\u001B[39m \u001B[43mgradient_f\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnew_param\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mset_xs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mset_ys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlambd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction_f\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39mnorm(act_gradient) \u001B[38;5;241m<\u001B[39m min_epsilon \u001B[38;5;129;01mor\u001B[39;00m act_step \u001B[38;5;241m>\u001B[39m max_steps:\n\u001B[0;32m      7\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m new_param\n",
      "Input \u001B[1;32mIn [9]\u001B[0m, in \u001B[0;36mgrad_j\u001B[1;34m(params, set_xs, set_ys, lambd, function_f)\u001B[0m\n\u001B[0;32m      5\u001B[0m partials \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros_like(params, dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat64)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# counting gradients for w1, w2, ..., wn\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m distances \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m np\u001B[38;5;241m.\u001B[39mmultiply(set_ys, \u001B[43mfunction_f\u001B[49m\u001B[43m(\u001B[49m\u001B[43mset_xs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m      9\u001B[0m distances \u001B[38;5;241m=\u001B[39m distances\u001B[38;5;241m.\u001B[39mreshape((distances\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m],))\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# sum = 2 * λ * wi + (0 or iyx) over all samples\u001B[39;00m\n",
      "Input \u001B[1;32mIn [8]\u001B[0m, in \u001B[0;36mf\u001B[1;34m(x, params)\u001B[0m\n\u001B[0;32m      2\u001B[0m b \u001B[38;5;241m=\u001B[39m params[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,:]\n\u001B[0;32m      3\u001B[0m W \u001B[38;5;241m=\u001B[39m params[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,:]\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43mW\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m b\n",
      "File \u001B[1;32m<__array_function__ internals>:180\u001B[0m, in \u001B[0;36mdot\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = validate_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    50\n",
       "-1    36\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_test).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.39605746e+03],\n",
       "       [-6.71778034e+02],\n",
       "       [ 1.15054477e+04],\n",
       "       [ 2.56168915e+03],\n",
       "       [ 4.27113273e+00],\n",
       "       [-8.49543611e+01],\n",
       "       [-1.50519592e+02],\n",
       "       [-5.74942435e+01],\n",
       "       [ 3.79854269e+00],\n",
       "       [ 8.77068016e+00],\n",
       "       [ 1.17598571e+01],\n",
       "       [-2.10088355e+01],\n",
       "       [-3.89976153e+02],\n",
       "       [-6.20431836e+03],\n",
       "       [-1.46888398e+00],\n",
       "       [-2.47697882e+01],\n",
       "       [-3.50312999e+01],\n",
       "       [-7.06221046e+00],\n",
       "       [-3.84809543e+00],\n",
       "       [-1.51190488e+00],\n",
       "       [ 2.57466856e+03],\n",
       "       [-2.42793558e+03],\n",
       "       [ 9.03459914e+03],\n",
       "       [-4.20244745e+03],\n",
       "       [-8.05246570e+00],\n",
       "       [-3.22491205e+02],\n",
       "       [-4.42874013e+02],\n",
       "       [-1.07890628e+02],\n",
       "       [-4.48809547e+01],\n",
       "       [-1.43400794e+01],\n",
       "       [-5.72050000e+02]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def get_success_percent(model_results, official_results):\n",
    "#     sum = 0\n",
    "#     for x, y in zip(model_results, official_results):\n",
    "#         if x==y:\n",
    "#             sum+=1\n",
    "#     fraction = sum / len(model_results)\n",
    "#     print(f\"Success percent: {100*fraction}%\")\n",
    "#\n",
    "# get_success_percent(results_testing_41, testing_setosa_versicolor_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model0 = np.zeros(shape=(31,1), dtype=np.float64)\n",
    "current_model = train_model(model0, X_train, y_train, 0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  650132.73644149],\n",
       "       [ 1228359.14425789],\n",
       "       [ 1465126.85839114],\n",
       "       [ 1117732.36169439],\n",
       "       [ 1522802.58091279],\n",
       "       [ 1075378.79974308],\n",
       "       [ 1431809.98140495],\n",
       "       [ 1229910.60180833],\n",
       "       [  581453.82015347],\n",
       "       [ 1138862.90043798],\n",
       "       [ 1255161.30610527],\n",
       "       [ 1189930.18371181],\n",
       "       [ 1067112.55510621],\n",
       "       [ 1382129.75905942],\n",
       "       [ 1230254.91771583],\n",
       "       [  610998.5481445 ],\n",
       "       [  917917.11408273],\n",
       "       [  248890.64002792],\n",
       "       [ 1677704.36092897],\n",
       "       [ -455434.09855369],\n",
       "       [  -89938.18479008],\n",
       "       [ 1314594.42608711],\n",
       "       [ 1358694.95737635],\n",
       "       [ 1039736.58862855],\n",
       "       [ 2134567.8611222 ],\n",
       "       [  980927.53699214],\n",
       "       [  982668.353319  ],\n",
       "       [ 1417924.12699632],\n",
       "       [ 1308881.68733822],\n",
       "       [ -878463.05643089],\n",
       "       [ 1359951.00553518],\n",
       "       [  -55241.04085472],\n",
       "       [ 1097822.70425327],\n",
       "       [  612472.80943222],\n",
       "       [ 1042583.63168814],\n",
       "       [  124427.81430182],\n",
       "       [ 1053572.88540195],\n",
       "       [  593282.92894417],\n",
       "       [ 1456429.52148342],\n",
       "       [  412063.67626153],\n",
       "       [  869362.43349886],\n",
       "       [  801094.85765816],\n",
       "       [  572987.21979695],\n",
       "       [ 1063945.1752577 ],\n",
       "       [ 1113936.74310293],\n",
       "       [ -182155.99360659],\n",
       "       [  958257.10351522],\n",
       "       [ 1287045.36454503],\n",
       "       [ 1224363.4621925 ],\n",
       "       [  815395.0629953 ],\n",
       "       [ 1224068.55017941],\n",
       "       [ 1586764.39050027],\n",
       "       [  142333.29768895],\n",
       "       [ 1172387.72260443],\n",
       "       [ 1205769.36091679],\n",
       "       [ 1194908.25807582],\n",
       "       [ 1188790.78372204],\n",
       "       [  948794.68309209],\n",
       "       [ 1143920.7676264 ],\n",
       "       [-1187676.63079239],\n",
       "       [  795026.06507859],\n",
       "       [  205819.04158404],\n",
       "       [ 1099658.93089692],\n",
       "       [ 1289541.65897893],\n",
       "       [  108542.96479233],\n",
       "       [  825238.84238421],\n",
       "       [ -938738.20559479],\n",
       "       [  190160.70562769],\n",
       "       [  718623.09302193],\n",
       "       [  895040.71293096],\n",
       "       [ 1012548.4619797 ],\n",
       "       [   42154.45149203],\n",
       "       [ 1123699.80405645],\n",
       "       [ 1355534.54157232],\n",
       "       [  363672.77322303],\n",
       "       [ 1143057.60714919],\n",
       "       [  942973.86098297],\n",
       "       [ 1363243.15173378],\n",
       "       [  955046.01855692],\n",
       "       [  669048.59709746],\n",
       "       [  937566.59774218],\n",
       "       [  855304.46375377],\n",
       "       [   25834.90082276],\n",
       "       [ 1282328.88281632],\n",
       "       [ 1036432.40795517],\n",
       "       [ 1280034.49112294]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(X_test, current_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6627906976744186"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(classify_y(X_test, f, current_model) == y_test) / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}