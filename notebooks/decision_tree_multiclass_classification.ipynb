{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import graphviz  ## REQUIRES GRAPHVIZ INSTALLED!\n",
    "from sklearn.tree import export_graphviz\n",
    "from typing import Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(\n",
    "        self,\n",
    "        depth: int,\n",
    "        split_attribute_idx: int = None,\n",
    "        split_attribute_name: str = None,\n",
    "        split_threshold: float = None,\n",
    "        entropy: float = None,\n",
    "        samples: int = None,\n",
    "        values: np.ndarray = None,\n",
    "        label: int = None,\n",
    "        label_name: str = None,\n",
    "    ) -> None:\n",
    "        self.depth = depth\n",
    "        self.split_attribute_idx = split_attribute_idx\n",
    "        self.split_attribute_name = split_attribute_name\n",
    "        self.split_threshold = split_threshold\n",
    "        self.entropy = entropy\n",
    "        self.samples = samples\n",
    "        self.values = values\n",
    "        self.label = label\n",
    "        self.label_name = label_name\n",
    "        self.right = None\n",
    "        self.left = None\n",
    "\n",
    "    def __str__(self):\n",
    "        node_str = f\"Depth: {self.depth}, \"\n",
    "        if self.split_attribute_name is not None:\n",
    "            node_str += f\"Split attribute: {self.split_attribute_name}, threshold: {self.split_threshold}, \"\n",
    "        elif self.split_attribute_idx is not None:\n",
    "            node_str += f\"Split attribute index: {self.split_attribute_idx}, threshold: {self.split_threshold}, \"\n",
    "        if self.label_name is not None:\n",
    "            node_str += f\"entropy: {self.entropy:.3f}, samples: {self.samples}, values: {self.values}, label: {self.label_name}\"\n",
    "        else:\n",
    "            node_str += f\"entropy: {self.entropy:.3f}, samples: {self.samples}, values: {self.values}, label: {self.label}\"\n",
    "        return node_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_depth: int,\n",
    "        min_entropy_diff: float,\n",
    "        min_node_size: int,\n",
    "        max_num_attributes: int = None,\n",
    "    ) -> None:\n",
    "        self.root = None\n",
    "        self.max_depth = max_depth\n",
    "        self.min_entropy_diff = min_entropy_diff\n",
    "        self.min_node_size = min_node_size\n",
    "        self.max_num_attributes = max_num_attributes\n",
    "\n",
    "    def _entropy(self, s: np.ndarray) -> float:\n",
    "        \"\"\"Calculates entropy of current dataset s\n",
    "        according to formula:\n",
    "        H(s) = sum(-p(x)*log2(p(x))),\n",
    "        where p(x) is the proportion of the number of elements\n",
    "        in class x to the number of elements in set s\n",
    "\n",
    "        Args:\n",
    "            s (np.ndarray): current dataset to calculate entropy on\n",
    "\n",
    "        Returns:\n",
    "            float: entropy of dataset s\n",
    "        \"\"\"\n",
    "        y = s[:, -1]\n",
    "        result = 0\n",
    "        counts = np.unique(y, return_counts=True)[1]\n",
    "        for count in counts:\n",
    "            proportion = count / y.shape[0]\n",
    "            result += -proportion * np.log2(proportion + 1e-5)\n",
    "        return result\n",
    "\n",
    "    def _find_split(\n",
    "        self, s: np.ndarray\n",
    "    ) -> Tuple[int, float, float, np.ndarray, np.ndarray]:\n",
    "        \"\"\"Finds best attribute and threshold to split node on\n",
    "\n",
    "        Args:\n",
    "            s (np.ndarray): current dataset of node\n",
    "\n",
    "        Returns:\n",
    "            Tuple[int, float, float, np.ndarray, np.ndarray]: split attribute index, threshold, split entropy, left subset, right subset\n",
    "        \"\"\"\n",
    "        min_split_entropy = np.inf\n",
    "        best_split_attr_idx = None\n",
    "        best_threshold = None\n",
    "        best_left_subset = None\n",
    "        best_right_subset = None\n",
    "\n",
    "        possible_attributes = (\n",
    "            range(s.shape[1] - 1)\n",
    "            if self.max_num_attributes is None\n",
    "            else np.random.choice(\n",
    "                range(s.shape[1] - 1), size=self.max_num_attributes, replace=False\n",
    "            )\n",
    "        )\n",
    "        for attribute_idx in possible_attributes:\n",
    "            for threshold in np.unique(s[:, attribute_idx]):\n",
    "\n",
    "                left_subset = np.array(\n",
    "                    [row for row in s if row[attribute_idx] < threshold]\n",
    "                )\n",
    "                right_subset = np.array(\n",
    "                    [row for row in s if row[attribute_idx] >= threshold]\n",
    "                )\n",
    "\n",
    "                left_entropy = (\n",
    "                    (len(left_subset) / len(s)) * self._entropy(left_subset)\n",
    "                    if left_subset.shape[0] > 0\n",
    "                    else 0\n",
    "                )\n",
    "                right_entropy = (\n",
    "                    (len(right_subset) / len(s)) * self._entropy(right_subset)\n",
    "                    if right_subset.shape[0] > 0\n",
    "                    else 0\n",
    "                )\n",
    "\n",
    "                split_entropy = left_entropy + right_entropy\n",
    "                if split_entropy < min_split_entropy:\n",
    "                    min_split_entropy = split_entropy\n",
    "                    best_split_attr_idx = attribute_idx\n",
    "                    best_threshold = threshold\n",
    "                    best_left_subset = left_subset\n",
    "                    best_right_subset = right_subset\n",
    "\n",
    "        return (\n",
    "            best_split_attr_idx,\n",
    "            best_threshold,\n",
    "            min_split_entropy,\n",
    "            best_left_subset,\n",
    "            best_right_subset,\n",
    "        )\n",
    "\n",
    "    def _build_id3(\n",
    "        self,\n",
    "        dataset: np.ndarray,\n",
    "        depth: int,\n",
    "        orig_classes: np.ndarray,\n",
    "        attribute_labels: np.ndarray = None,\n",
    "        class_labels: np.ndarray = None,\n",
    "    ) -> Node:\n",
    "        if dataset.shape[0] == 0:\n",
    "            return None\n",
    "\n",
    "        X, y = dataset[:, :-1], dataset[:, -1].astype(\"int64\")\n",
    "\n",
    "        # all examples classified as one class\n",
    "        if np.unique(y).shape[0] == 1:\n",
    "            return Node(\n",
    "                depth=depth,\n",
    "                values=[y.tolist().count(c) for c in orig_classes],\n",
    "                entropy=0.0,\n",
    "                label=np.argmax([y.tolist().count(c) for c in orig_classes]),\n",
    "                label_name=class_labels[\n",
    "                    np.argmax([y.tolist().count(c) for c in orig_classes])\n",
    "                ]\n",
    "                if class_labels is not None\n",
    "                else np.argmax([y.tolist().count(c) for c in orig_classes]),\n",
    "                samples=dataset.shape[0],\n",
    "            )\n",
    "\n",
    "        # no attributes to split upon\n",
    "        if X.shape[1] == 0:\n",
    "            return Node(\n",
    "                depth=depth,\n",
    "                values=[y.tolist().count(c) for c in orig_classes],\n",
    "                entropy=self._entropy(dataset),\n",
    "                label=np.argmax([y.tolist().count(c) for c in orig_classes]),\n",
    "                label_name=class_labels[\n",
    "                    np.argmax([y.tolist().count(c) for c in orig_classes])\n",
    "                ]\n",
    "                if class_labels is not None\n",
    "                else np.argmax([y.tolist().count(c) for c in orig_classes]),\n",
    "                samples=dataset.shape[0],\n",
    "            )\n",
    "\n",
    "        (\n",
    "            best_split_attr_idx,\n",
    "            best_threshold,\n",
    "            min_split_entropy,\n",
    "            best_left_subset,\n",
    "            best_right_subset,\n",
    "        ) = self._find_split(dataset)\n",
    "\n",
    "        # decide about splitting\n",
    "        if (\n",
    "            depth < self.max_depth\n",
    "            and (self._entropy(dataset) - min_split_entropy) > self.min_entropy_diff\n",
    "            and (best_left_subset.shape[0] > self.min_node_size)\n",
    "            and (best_right_subset.shape[0] > self.min_node_size)\n",
    "        ):\n",
    "            root = Node(\n",
    "                depth=depth,\n",
    "                split_attribute_idx=best_split_attr_idx,\n",
    "                split_attribute_name=attribute_labels[best_split_attr_idx]\n",
    "                if attribute_labels is not None\n",
    "                else None,\n",
    "                split_threshold=best_threshold,\n",
    "                entropy=self._entropy(dataset),\n",
    "                samples=dataset.shape[0],\n",
    "                values=[y.tolist().count(c) for c in orig_classes],\n",
    "                label=np.argmax([y.tolist().count(c) for c in orig_classes]),\n",
    "                label_name=class_labels[\n",
    "                    np.argmax([y.tolist().count(c) for c in orig_classes])\n",
    "                ]\n",
    "                if class_labels is not None\n",
    "                else np.argmax([y.tolist().count(c) for c in orig_classes]),\n",
    "            )\n",
    "            root.left = self._build_id3(\n",
    "                best_left_subset,\n",
    "                depth=depth + 1,\n",
    "                orig_classes=orig_classes,\n",
    "                attribute_labels=attribute_labels,\n",
    "                class_labels=class_labels,\n",
    "            )\n",
    "            root.right = self._build_id3(\n",
    "                best_right_subset,\n",
    "                depth=depth + 1,\n",
    "                orig_classes=orig_classes,\n",
    "                attribute_labels=attribute_labels,\n",
    "                class_labels=class_labels,\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            root = Node(\n",
    "                depth=depth,\n",
    "                entropy=self._entropy(dataset),\n",
    "                samples=dataset.shape[0],\n",
    "                values=[y.tolist().count(c) for c in orig_classes],\n",
    "                label=np.argmax([y.tolist().count(c) for c in orig_classes]),\n",
    "                label_name=class_labels[\n",
    "                    np.argmax([y.tolist().count(c) for c in orig_classes])\n",
    "                ]\n",
    "                if class_labels is not None\n",
    "                else np.argmax([y.tolist().count(c) for c in orig_classes]),\n",
    "            )\n",
    "\n",
    "        return root\n",
    "\n",
    "    def visualize(self) -> None:\n",
    "        queue = list()\n",
    "        queue.append(self.root)\n",
    "\n",
    "        while queue:\n",
    "            v = queue.pop(0)\n",
    "            print(v)\n",
    "            if v.left is not None:\n",
    "                queue.append(v.left)\n",
    "            if v.left is not None:\n",
    "                queue.append(v.right)\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        attribute_labels: np.ndarray = None,\n",
    "        class_labels: np.ndarray = None,\n",
    "    ) -> None:\n",
    "        if attribute_labels is not None:\n",
    "            if attribute_labels.shape[0] != X.shape[1]:\n",
    "                raise Exception(\"Invalid shape of given attribute labels\")\n",
    "\n",
    "        if class_labels is not None:\n",
    "            if class_labels.shape[0] != np.unique(y).shape[0]:\n",
    "                raise Exception(\"Invalid shape of given class labels\")\n",
    "\n",
    "        if len(y.shape) == 1:\n",
    "            y = np.expand_dims(y, axis=1)\n",
    "\n",
    "        dataset = np.concatenate([X, y], axis=1)\n",
    "        self.root = self._build_id3(\n",
    "            dataset,\n",
    "            depth=0,\n",
    "            orig_classes=np.unique(y),\n",
    "            attribute_labels=attribute_labels,\n",
    "            class_labels=class_labels,\n",
    "        )\n",
    "\n",
    "    def _predict_sample(self, sample: np.ndarray) -> int:\n",
    "        current_node = self.root\n",
    "        current_prediction = current_node.label\n",
    "        while current_node.split_attribute_idx is not None:\n",
    "            if sample[current_node.split_attribute_idx] < current_node.split_threshold:\n",
    "                current_prediction = current_node.left.label\n",
    "                current_node = current_node.left\n",
    "            else:\n",
    "                current_prediction = current_node.right.label\n",
    "                current_node = current_node.right\n",
    "\n",
    "        return current_prediction\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        if len(X.shape) == 1:\n",
    "            X = np.expand_dims(X, axis=0)\n",
    "\n",
    "        if self.root is not None:\n",
    "            return np.array([self._predict_sample(sample) for sample in X])\n",
    "        else:\n",
    "            raise Exception(\"Decision Tree is not trained yet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTree(max_depth=3, min_entropy_diff=0.01, min_node_size=30)\n",
    "tree.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    attribute_labels=np.array(data.feature_names),\n",
    "    class_labels=data.target_names,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 0, Split attribute: petal length (cm), threshold: 3.0, entropy: 1.585, samples: 120, values: [40, 41, 39], label: versicolor\n",
      "Depth: 1, entropy: 0.000, samples: 40, values: [40, 0, 0], label: setosa\n",
      "Depth: 1, Split attribute: petal length (cm), threshold: 4.8, entropy: 1.000, samples: 80, values: [0, 41, 39], label: versicolor\n",
      "Depth: 2, entropy: 0.179, samples: 37, values: [0, 36, 1], label: versicolor\n",
      "Depth: 2, entropy: 0.519, samples: 43, values: [0, 5, 38], label: virginica\n"
     ]
    }
   ],
   "source": [
    "tree.visualize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tree.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model from Sklearn for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_decision_tree = DecisionTreeClassifier(\n",
    "    criterion=\"entropy\",\n",
    "    max_depth=3,\n",
    "    min_samples_split=30,\n",
    "    random_state=42,\n",
    "    min_samples_leaf=30,\n",
    "    min_impurity_decrease=0.01,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=3,\n",
       "                       min_impurity_decrease=0.01, min_samples_leaf=30,\n",
       "                       min_samples_split=30, random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_decision_tree.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 3.0.0 (20220226.1711)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"366pt\" height=\"314pt\"\n viewBox=\"0.00 0.00 366.00 314.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 310)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-310 362,-310 362,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#fdfffd\" stroke=\"black\" d=\"M218.5,-306C218.5,-306 68.5,-306 68.5,-306 62.5,-306 56.5,-300 56.5,-294 56.5,-294 56.5,-235 56.5,-235 56.5,-229 62.5,-223 68.5,-223 68.5,-223 218.5,-223 218.5,-223 224.5,-223 230.5,-229 230.5,-235 230.5,-235 230.5,-294 230.5,-294 230.5,-300 224.5,-306 218.5,-306\"/>\n<text text-anchor=\"middle\" x=\"143.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) &lt;= 2.45</text>\n<text text-anchor=\"middle\" x=\"143.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.585</text>\n<text text-anchor=\"middle\" x=\"143.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 120</text>\n<text text-anchor=\"middle\" x=\"143.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [40, 41, 39]</text>\n<text text-anchor=\"middle\" x=\"143.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M109,-179.5C109,-179.5 12,-179.5 12,-179.5 6,-179.5 0,-173.5 0,-167.5 0,-167.5 0,-123.5 0,-123.5 0,-117.5 6,-111.5 12,-111.5 12,-111.5 109,-111.5 109,-111.5 115,-111.5 121,-117.5 121,-123.5 121,-123.5 121,-167.5 121,-167.5 121,-173.5 115,-179.5 109,-179.5\"/>\n<text text-anchor=\"middle\" x=\"60.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"60.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 40</text>\n<text text-anchor=\"middle\" x=\"60.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [40, 0, 0]</text>\n<text text-anchor=\"middle\" x=\"60.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M114.7,-222.91C106.72,-211.65 98.04,-199.42 90.02,-188.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"92.67,-185.8 84.03,-179.67 86.96,-189.85 92.67,-185.8\"/>\n<text text-anchor=\"middle\" x=\"79.84\" y=\"-200.61\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#f5fef9\" stroke=\"black\" d=\"M301.5,-187C301.5,-187 151.5,-187 151.5,-187 145.5,-187 139.5,-181 139.5,-175 139.5,-175 139.5,-116 139.5,-116 139.5,-110 145.5,-104 151.5,-104 151.5,-104 301.5,-104 301.5,-104 307.5,-104 313.5,-110 313.5,-116 313.5,-116 313.5,-175 313.5,-175 313.5,-181 307.5,-187 301.5,-187\"/>\n<text text-anchor=\"middle\" x=\"226.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) &lt;= 4.75</text>\n<text text-anchor=\"middle\" x=\"226.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.0</text>\n<text text-anchor=\"middle\" x=\"226.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 80</text>\n<text text-anchor=\"middle\" x=\"226.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 41, 39]</text>\n<text text-anchor=\"middle\" x=\"226.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 0&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>0&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M172.3,-222.91C178.61,-214.01 185.35,-204.51 191.86,-195.33\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"194.82,-197.2 197.75,-187.02 189.11,-193.15 194.82,-197.2\"/>\n<text text-anchor=\"middle\" x=\"201.94\" y=\"-207.97\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#3ee684\" stroke=\"black\" d=\"M207,-68C207,-68 104,-68 104,-68 98,-68 92,-62 92,-56 92,-56 92,-12 92,-12 92,-6 98,0 104,0 104,0 207,0 207,0 213,0 219,-6 219,-12 219,-12 219,-56 219,-56 219,-62 213,-68 207,-68\"/>\n<text text-anchor=\"middle\" x=\"155.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.179</text>\n<text text-anchor=\"middle\" x=\"155.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 37</text>\n<text text-anchor=\"middle\" x=\"155.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 36, 1]</text>\n<text text-anchor=\"middle\" x=\"155.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M200.06,-103.73C194.38,-94.97 188.38,-85.7 182.67,-76.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"185.47,-74.79 177.09,-68.3 179.6,-78.59 185.47,-74.79\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#9253e8\" stroke=\"black\" d=\"M346,-68C346,-68 249,-68 249,-68 243,-68 237,-62 237,-56 237,-56 237,-12 237,-12 237,-6 243,0 249,0 249,0 346,0 346,0 352,0 358,-6 358,-12 358,-12 358,-56 358,-56 358,-62 352,-68 346,-68\"/>\n<text text-anchor=\"middle\" x=\"297.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.519</text>\n<text text-anchor=\"middle\" x=\"297.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 43</text>\n<text text-anchor=\"middle\" x=\"297.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 5, 38]</text>\n<text text-anchor=\"middle\" x=\"297.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M252.94,-103.73C258.62,-94.97 264.62,-85.7 270.33,-76.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"273.4,-78.59 275.91,-68.3 267.53,-74.79 273.4,-78.59\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.sources.Source at 0x20b0073d2d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = export_graphviz(\n",
    "    sklearn_decision_tree,\n",
    "    out_file=None,\n",
    "    feature_names=data.feature_names,\n",
    "    class_names=data.target_names,\n",
    "    rounded=True,\n",
    "    proportion=False,\n",
    "    filled=True,\n",
    ")\n",
    "graphviz.Source(graph, format=\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_sklearn = sklearn_decision_tree.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions_sklearn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3387639f90ff78668b9166b82532e0a4254e4114bba40ba72563f9784614f2c3"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
