{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Lib"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "      0      1       2       3        4        5       6        7       8   \\\n0  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710  0.2419   \n1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017  0.1812   \n2  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790  0.2069   \n3  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520  0.2597   \n4  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430  0.1809   \n\n        9   ...     20     21      22      23      24      25      26      27  \\\n0  0.07871  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n1  0.05667  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n2  0.05999  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n3  0.09744  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n4  0.05883  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n\n       28       29  \n0  0.4601  0.11890  \n1  0.2750  0.08902  \n2  0.3613  0.08758  \n3  0.6638  0.17300  \n4  0.2364  0.07678  \n\n[5 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>25</th>\n      <th>26</th>\n      <th>27</th>\n      <th>28</th>\n      <th>29</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>0.2419</td>\n      <td>0.07871</td>\n      <td>...</td>\n      <td>25.38</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>0.1812</td>\n      <td>0.05667</td>\n      <td>...</td>\n      <td>24.99</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>0.2069</td>\n      <td>0.05999</td>\n      <td>...</td>\n      <td>23.57</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>0.2597</td>\n      <td>0.09744</td>\n      <td>...</td>\n      <td>14.91</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>0.1809</td>\n      <td>0.05883</td>\n      <td>...</td>\n      <td>22.54</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X).head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "(569,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "def change_to_correct_targets(arr):\n",
    "    new_arr = copy.copy(arr)\n",
    "    new_arr[np.where(arr > 0)] = 1\n",
    "    new_arr[np.where(arr <= 0)] = -1\n",
    "    return new_arr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "y = change_to_correct_targets(y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=42\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "y_train = np.expand_dims(y_train, axis=1)\n",
    "y_test = np.expand_dims(y_test, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Problem definition\n",
    "### 3.1. Ogólnie\n",
    "Zadanie polega na znalezieniu funkcji $$ f(x)={w^{T}x+b}$$, która tworzy hiperpłaszczyznę zapewniającą klasyfikację (dopuszczającą pomyłki) z użyciem maszyny wektorów nośnych SVM. Otrzymana funkcja powinna zapewniać jak najmniejszą liczbę pomyłek przy klasyfikowaniu elementów zbioru BREAST CANCER do odpowiedniej klasy.\n",
    "\n",
    "Klasyfikacja odbywa się poprzez zwrócenie dla danego zestawu cech $x$ grupy $y(x) = -1 \\lor y(x) = 1$, do której należy za pomocą funkcji:\n",
    "\n",
    "$$\n",
    "y(x) =\n",
    "{\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "-1 & \\textrm{, $f(x) \\leq 0$}\\\\\n",
    "1 & \\textrm{, $f(x) > 0$}\n",
    "\\end{array}\n",
    "\\right\n",
    "}\n",
    "$$\n",
    "\n",
    "\n",
    "Aby otrzymać funkcję $f(x)$ należy znaleźć parametry $w$ i $b$, które minimalizują funkcję straty:\n",
    "$$ J(w,b)=\\Sigma_i(max(1-f(x_i)y_i, 0)) + \\lambda*||w||^2 $$\n",
    "\n",
    "Aby zoptymalizować owe parametry, zastosowana zostanie metoda gradientu prostego, w tym celu potrzebny będzie gradient funkcji $J(w,b)$:\n",
    "$$\n",
    "\\nabla J =\n",
    "\\begin{bmatrix}\n",
    "    \\partial J \\over \\partial w_1 \\\\\n",
    "    \\vdots \\\\\n",
    "    \\partial J \\over \\partial w_n \\\\\n",
    "    \\partial J \\over \\partial b \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Natomiast pochodne cząstkowe te prezentują się następująco:\n",
    "$$\n",
    "{\\partial J \\over \\partial w_i}=\n",
    "{\\lambda*2*w_i} + \\Sigma_k(1 \\cdot\n",
    "{\\left\\{ \\begin{array}{ll}\n",
    "0 & \\textrm{, $ 1-f(x_k)y_k \\leq 0$ }\\\\\n",
    "-y_k \\cdot x_{k[i]} & \\textrm{, $ 1-f(x_k)y_k > 0$}\n",
    "\\end{array}\\right })\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "{\\partial J \\over \\partial b}=\n",
    "\\Sigma_k (1 * {\n",
    "\\left\\{ \\begin{array}{ll}\n",
    "0 & \\textrm{, $ 1-f(x_k) \\cdot y_k \\leq 0$ }\\\\\n",
    "y_k & \\textrm{, $ 1-f(x_k) \\cdot y_k > 0$}\n",
    "\\end{array}\\right\n",
    "}\n",
    ")\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Functions to train:\n",
    "+ funkcja **f(x)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, params):\n",
    "    b = params[-1,:]\n",
    "    W = params[:-1,:]\n",
    "    return np.dot(x,W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ gradient **J(w, b)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "d = np.array([[3],[2],[-2],[5]])\n",
    "d = d.reshape((4,))\n",
    "y = np.array([[1,1,1,1]])\n",
    "x = np.array([\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 6, 7, 8],\n",
    "    [9, 10, 11, 12],\n",
    "    [13, 14, 15, 16]\n",
    "])\n",
    "\n",
    "x[np.where(d<0)] -= y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "(4,)"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "(1, 4)"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "(4, 4)"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "def grad_j(params, set_xs, set_ys, lambd, function_f):\n",
    "    # numpy array of partial derivatives\n",
    "    b = params[-1,:]\n",
    "    W = params[:-1,:]\n",
    "    partials = np.zeros_like(params, dtype=np.float64)\n",
    "\n",
    "    # counting gradients for w1, w2, ..., wn\n",
    "    distances = 1 - np.multiply(set_ys, function_f(set_xs, params))\n",
    "    distances = distances.reshape((distances.shape[0],))\n",
    "    # sum = 2 * λ * wi + (0 or iyx) over all samples\n",
    "    x_w_part = np.zeros_like(set_xs)\n",
    "    x_w_part[np.where(distances>0)] -= (set_ys*set_xs)[np.where(distances>0)]\n",
    "    partials[:-1,:] = 2*lambd*W + np.sum(x_w_part,axis=0).reshape(partials[:-1,:].shape)\n",
    "\n",
    "    # counting gradient for b\n",
    "    x_b_part = np.zeros_like(set_ys, dtype=np.float64)\n",
    "    x_b_part[np.where(distances>0)] += set_ys[np.where(distances>0)]\n",
    "    partials[-1,:] = np.sum(x_b_part, axis=0)\n",
    "\n",
    "    return partials"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ algorytm realizujący metodę gradientu prostego:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(function_f, gradient_f, params, beta, set_xs, set_ys, lambd, max_steps=10000, min_epsilon = 1e-10):\n",
    "    new_param = params\n",
    "    act_step = 0\n",
    "    while 1:\n",
    "        act_gradient = gradient_f(new_param, set_xs, set_ys, lambd, function_f)\n",
    "        if np.linalg.norm(act_gradient) < min_epsilon or act_step > max_steps:\n",
    "            return new_param\n",
    "        new_param = new_param - beta * act_gradient\n",
    "        act_step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Functions to evaluate:\n",
    "+ funkcja **y(x)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_y(x, function_f, params):\n",
    "    return change_to_correct_targets(function_f(x, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train & test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ dodatkowo zostaną zdefiniowane funkcje: trenujące model (**train_model()**) oraz wykonujące walidacje dla hiperparametru lambda(**validate_model()**)\n",
    "+ a także zostanie zdefiniowany zbiór możliwych lambd **lambdas = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5]**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5]\n",
    "\n",
    "def train_model(model0, training_set_x, training_set_y, param_lambda):\n",
    "    return gradient_descent(f, grad_j, model0, 0.1, training_set_x, training_set_y, param_lambda)\n",
    "\n",
    "def validate_model(training_set_x, training_set_y, validating_set_x, validating_set_y):\n",
    "    best_model = None\n",
    "    best_lambda = None\n",
    "    best_score = - math.inf\n",
    "\n",
    "    for param_lambda in lambdas:\n",
    "        model0 = np.zeros(shape=(31,1), dtype=np.float64)\n",
    "        current_model = train_model(model0, training_set_x, training_set_y, param_lambda)\n",
    "        # results_validating = np.zeros(len(validating_set_y), dtype='int')\n",
    "        results_validating = classify_y(validating_set_x, f, current_model)\n",
    "        n_of_successes = 0\n",
    "        for x, y in zip(results_validating, validating_set_y):\n",
    "            if x == y:\n",
    "                n_of_successes += 1\n",
    "        print(f\"Validating model with lambda: {param_lambda} gave score: {n_of_successes / len(results_validating)}\")\n",
    "        # as long as new score is not worse than actual best, lambda should be maximized\n",
    "        if (n_of_successes / len(results_validating) >= best_score):      \n",
    "            best_score = n_of_successes / len(results_validating)\n",
    "            best_lambda = param_lambda\n",
    "            best_model = current_model\n",
    "    print(f\"Best lambda for this validation equals: {best_lambda} with score: {best_score}\")\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating model with lambda: 0.0001 gave score: 0.9534883720930233\n",
      "Validating model with lambda: 0.0005 gave score: 0.9534883720930233\n",
      "Validating model with lambda: 0.001 gave score: 0.9418604651162791\n",
      "Validating model with lambda: 0.005 gave score: 0.43023255813953487\n",
      "Validating model with lambda: 0.01 gave score: 0.6046511627906976\n",
      "Validating model with lambda: 0.05 gave score: 0.6744186046511628\n",
      "Validating model with lambda: 0.1 gave score: 0.7906976744186046\n",
      "Validating model with lambda: 0.5 gave score: 0.37209302325581395\n",
      "Validating model with lambda: 1 gave score: 0.627906976744186\n",
      "Validating model with lambda: 5 gave score: 0.37209302325581395\n",
      "Best lambda for this validation equals: 0.0005 with score: 0.9534883720930233\n"
     ]
    }
   ],
   "source": [
    "model = validate_model(X_train, y_train, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 2.60916322e+04],\n       [-1.21148491e+04],\n       [ 1.24725422e+05],\n       [ 2.82351751e+04],\n       [ 4.63760557e+01],\n       [-9.28372375e+02],\n       [-1.61012645e+03],\n       [-6.21384132e+02],\n       [ 8.25482672e+01],\n       [ 9.78198310e+01],\n       [ 1.45123217e+02],\n       [ 1.99632134e+02],\n       [-4.38519759e+03],\n       [-6.32856660e+04],\n       [-1.70651615e+01],\n       [-2.53361149e+02],\n       [-3.61313966e+02],\n       [-7.67698771e+01],\n       [-3.89216426e+01],\n       [-1.52994886e+01],\n       [ 2.78230766e+04],\n       [-2.97855716e+04],\n       [ 9.97253232e+04],\n       [-4.72898615e+04],\n       [-8.47749010e+01],\n       [-3.39401537e+03],\n       [-4.60171008e+03],\n       [-1.11275165e+03],\n       [-4.50580654e+02],\n       [-1.37852532e+02],\n       [-6.15320000e+03]])"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success percent: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# def get_success_percent(model_results, official_results):\n",
    "#     sum = 0\n",
    "#     for x, y in zip(model_results, official_results):\n",
    "#         if x==y:\n",
    "#             sum+=1\n",
    "#     fraction = sum / len(model_results)\n",
    "#     print(f\"Success percent: {100*fraction}%\")\n",
    "#\n",
    "# get_success_percent(results_testing_41, testing_setosa_versicolor_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "model0 = np.zeros(shape=(31,1), dtype=np.float64)\n",
    "current_model = train_model(model0, X_train, y_train, 0.0005)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[  -912352.44914335],\n       [-30351848.89083805],\n       [-11532753.87949219],\n       [  6704905.52847487],\n       [  5439833.89106685],\n       [-20286073.08056055],\n       [-33637297.88012215],\n       [ -6905237.25786767],\n       [  5090560.73677426],\n       [  3148125.11131515],\n       [  3144284.86976641],\n       [-12197153.4950769 ],\n       [  3376846.24422615],\n       [ -1798489.14207149],\n       [  4457972.78867497],\n       [ -3736253.3217007 ],\n       [  4011725.3556323 ],\n       [  5785754.84724928],\n       [  4805085.75493265],\n       [-20837742.06586811],\n       [ -1134354.72295623],\n       [  2973828.11025815],\n       [-28508535.54695708],\n       [  4441063.11581877],\n       [  4863492.88976447],\n       [  5385711.4466321 ],\n       [  5213510.73231261],\n       [  5559319.51158674],\n       [  4183469.56247255],\n       [-28522258.37164116],\n       [  5077988.82313144],\n       [  4565876.51720452],\n       [  1913910.76457567],\n       [  -353359.96781326],\n       [  5091806.41395157],\n       [  3175486.41454032],\n       [ -9622755.56952278],\n       [  2078405.72108333],\n       [-19775933.19344067],\n       [   279477.94649931],\n       [  4436755.55680377],\n       [ -9541849.7246146 ],\n       [  5465535.65081799],\n       [  2774622.3576804 ],\n       [  4151925.6704714 ],\n       [  2588427.10910466],\n       [  4654642.21869186],\n       [  3365241.11786225],\n       [  2360100.81419058],\n       [  4547536.35240603],\n       [-16754859.54683593],\n       [-23550028.95809161],\n       [  4123797.91843828],\n       [  3869105.7376096 ],\n       [  4868050.03453562],\n       [  1393657.27098647],\n       [  4443062.65746496],\n       [-33077939.75377425],\n       [  1069207.55149136],\n       [  5285939.50149435],\n       [  2886041.90094302],\n       [-21258633.43260235],\n       [-29694670.03303294],\n       [  3233033.63869855],\n       [  4280509.81817928],\n       [  2009880.89980507],\n       [-15828813.94414432],\n       [-14168071.46574615],\n       [  5016424.71707897],\n       [  3477245.88374639],\n       [ -2741028.86066689],\n       [-16346718.25523862],\n       [  4642651.58093847],\n       [   877146.57131402],\n       [  3002130.92000413],\n       [  3785449.4850118 ],\n       [  2422621.80154937],\n       [ -2194469.36014414],\n       [  4115933.72730646],\n       [  4838537.62694068],\n       [ -9547407.02376144],\n       [  3645894.84635987],\n       [  -170388.47419577],\n       [-31328703.49329168],\n       [ -9576245.53468775],\n       [ -2746348.19645837]])"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(X_test, current_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9534883720930233"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(classify_y(X_test, f, current_model) == y_test) / y_test.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}