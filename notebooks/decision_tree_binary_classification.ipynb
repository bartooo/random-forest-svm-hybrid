{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import graphviz  ## REQUIRES GRAPHVIZ INSTALLED!\n",
    "from sklearn.tree import export_graphviz\n",
    "from typing import Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 30), (569,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(\n",
    "        self,\n",
    "        depth: int,\n",
    "        split_attribute_idx: int = None,\n",
    "        split_attribute_name: str = None,\n",
    "        split_threshold: float = None,\n",
    "        entropy: float = None,\n",
    "        samples: int = None,\n",
    "        values: np.ndarray = None,\n",
    "        label: int = None,\n",
    "        label_name: str = None,\n",
    "    ) -> None:\n",
    "        self.depth = depth\n",
    "        self.split_attribute_idx = split_attribute_idx\n",
    "        self.split_attribute_name = split_attribute_name\n",
    "        self.split_threshold = split_threshold\n",
    "        self.entropy = entropy\n",
    "        self.samples = samples\n",
    "        self.values = values\n",
    "        self.label = label\n",
    "        self.label_name = label_name\n",
    "        self.right = None\n",
    "        self.left = None\n",
    "\n",
    "    def __str__(self):\n",
    "        node_str = f\"Depth: {self.depth}, \"\n",
    "        if self.split_attribute_name is not None:\n",
    "            node_str += f\"Split attribute: {self.split_attribute_name}, threshold: {self.split_threshold}, \"\n",
    "        elif self.split_attribute_idx is not None:\n",
    "            node_str += f\"Split attribute index: {self.split_attribute_idx}, threshold: {self.split_threshold}, \"\n",
    "        if self.label_name is not None:\n",
    "            node_str += f\"entropy: {self.entropy:.3f}, samples: {self.samples}, values: {self.values}, label: {self.label_name}\"\n",
    "        else:\n",
    "            node_str += f\"entropy: {self.entropy:.3f}, samples: {self.samples}, values: {self.values}, label: {self.label}\"\n",
    "        return node_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_depth: int,\n",
    "        min_entropy_diff: float,\n",
    "        min_node_size: int,\n",
    "        max_num_attributes: int = None,\n",
    "    ) -> None:\n",
    "        self.root = None\n",
    "        self.max_depth = max_depth\n",
    "        self.min_entropy_diff = min_entropy_diff\n",
    "        self.min_node_size = min_node_size\n",
    "        self.max_num_attributes = max_num_attributes\n",
    "\n",
    "    def _entropy(self, s: np.ndarray) -> float:\n",
    "        \"\"\"Calculates entropy of current dataset s\n",
    "        according to formula:\n",
    "        H(s) = sum(-p(x)*log2(p(x))),\n",
    "        where p(x) is the proportion of the number of elements\n",
    "        in class x to the number of elements in set s\n",
    "\n",
    "        Args:\n",
    "            s (np.ndarray): current dataset to calculate entropy on\n",
    "\n",
    "        Returns:\n",
    "            float: entropy of dataset s\n",
    "        \"\"\"\n",
    "        y = s[:, -1]\n",
    "        result = 0\n",
    "        counts = np.unique(y, return_counts=True)[1]\n",
    "        for count in counts:\n",
    "            proportion = count / y.shape[0]\n",
    "            result += -proportion * np.log2(proportion + 1e-5)\n",
    "        return result\n",
    "\n",
    "    def _find_split(\n",
    "        self, s: np.ndarray\n",
    "    ) -> Tuple[int, float, float, np.ndarray, np.ndarray]:\n",
    "        \"\"\"Finds best attribute and threshold to split node on\n",
    "\n",
    "        Args:\n",
    "            s (np.ndarray): current dataset of node\n",
    "\n",
    "        Returns:\n",
    "            Tuple[int, float, float, np.ndarray, np.ndarray]: split attribute index, threshold, split entropy, left subset, right subset\n",
    "        \"\"\"\n",
    "        min_split_entropy = np.inf\n",
    "        best_split_attr_idx = None\n",
    "        best_threshold = None\n",
    "        best_left_subset = None\n",
    "        best_right_subset = None\n",
    "\n",
    "        possible_attributes = (\n",
    "            range(s.shape[1] - 1)\n",
    "            if self.max_num_attributes is None\n",
    "            else np.random.choice(\n",
    "                range(s.shape[1] - 1), size=self.max_num_attributes, replace=False\n",
    "            )\n",
    "        )\n",
    "        for attribute_idx in possible_attributes:\n",
    "            for threshold in np.unique(s[:, attribute_idx]):\n",
    "\n",
    "                left_subset = np.array(\n",
    "                    [row for row in s if row[attribute_idx] < threshold]\n",
    "                )\n",
    "                right_subset = np.array(\n",
    "                    [row for row in s if row[attribute_idx] >= threshold]\n",
    "                )\n",
    "\n",
    "                left_entropy = (\n",
    "                    (len(left_subset) / len(s)) * self._entropy(left_subset)\n",
    "                    if left_subset.shape[0] > 0\n",
    "                    else 0\n",
    "                )\n",
    "                right_entropy = (\n",
    "                    (len(right_subset) / len(s)) * self._entropy(right_subset)\n",
    "                    if right_subset.shape[0] > 0\n",
    "                    else 0\n",
    "                )\n",
    "\n",
    "                split_entropy = left_entropy + right_entropy\n",
    "                if split_entropy < min_split_entropy:\n",
    "                    min_split_entropy = split_entropy\n",
    "                    best_split_attr_idx = attribute_idx\n",
    "                    best_threshold = threshold\n",
    "                    best_left_subset = left_subset\n",
    "                    best_right_subset = right_subset\n",
    "\n",
    "        return (\n",
    "            best_split_attr_idx,\n",
    "            best_threshold,\n",
    "            min_split_entropy,\n",
    "            best_left_subset,\n",
    "            best_right_subset,\n",
    "        )\n",
    "\n",
    "    def _build_id3(\n",
    "        self,\n",
    "        dataset: np.ndarray,\n",
    "        depth: int,\n",
    "        orig_classes: np.ndarray,\n",
    "        attribute_labels: np.ndarray = None,\n",
    "        class_labels: np.ndarray = None,\n",
    "    ) -> Node:\n",
    "        if dataset.shape[0] == 0:\n",
    "            return None\n",
    "\n",
    "        X, y = dataset[:, :-1], dataset[:, -1].astype(\"int64\")\n",
    "\n",
    "        # all examples classified as one class\n",
    "        if np.unique(y).shape[0] == 1:\n",
    "            return Node(\n",
    "                depth=depth,\n",
    "                values=[y.tolist().count(c) for c in orig_classes],\n",
    "                entropy=0.0,\n",
    "                label=np.argmax([y.tolist().count(c) for c in orig_classes]),\n",
    "                label_name=class_labels[\n",
    "                    np.argmax([y.tolist().count(c) for c in orig_classes])\n",
    "                ]\n",
    "                if class_labels is not None\n",
    "                else np.argmax([y.tolist().count(c) for c in orig_classes]),\n",
    "                samples=dataset.shape[0],\n",
    "            )\n",
    "\n",
    "        # no attributes to split upon\n",
    "        if X.shape[1] == 0:\n",
    "            return Node(\n",
    "                depth=depth,\n",
    "                values=[y.tolist().count(c) for c in orig_classes],\n",
    "                entropy=self._entropy(dataset),\n",
    "                label=np.argmax([y.tolist().count(c) for c in orig_classes]),\n",
    "                label_name=class_labels[\n",
    "                    np.argmax([y.tolist().count(c) for c in orig_classes])\n",
    "                ]\n",
    "                if class_labels is not None\n",
    "                else np.argmax([y.tolist().count(c) for c in orig_classes]),\n",
    "                samples=dataset.shape[0],\n",
    "            )\n",
    "\n",
    "        (\n",
    "            best_split_attr_idx,\n",
    "            best_threshold,\n",
    "            min_split_entropy,\n",
    "            best_left_subset,\n",
    "            best_right_subset,\n",
    "        ) = self._find_split(dataset)\n",
    "\n",
    "        # decide about splitting\n",
    "        if (\n",
    "            depth < self.max_depth\n",
    "            and (self._entropy(dataset) - min_split_entropy) > self.min_entropy_diff\n",
    "            and (best_left_subset.shape[0] > self.min_node_size)\n",
    "            and (best_right_subset.shape[0] > self.min_node_size)\n",
    "        ):\n",
    "            root = Node(\n",
    "                depth=depth,\n",
    "                split_attribute_idx=best_split_attr_idx,\n",
    "                split_attribute_name=attribute_labels[best_split_attr_idx]\n",
    "                if attribute_labels is not None\n",
    "                else None,\n",
    "                split_threshold=best_threshold,\n",
    "                entropy=self._entropy(dataset),\n",
    "                samples=dataset.shape[0],\n",
    "                values=[y.tolist().count(c) for c in orig_classes],\n",
    "                label=np.argmax([y.tolist().count(c) for c in orig_classes]),\n",
    "                label_name=class_labels[\n",
    "                    np.argmax([y.tolist().count(c) for c in orig_classes])\n",
    "                ]\n",
    "                if class_labels is not None\n",
    "                else np.argmax([y.tolist().count(c) for c in orig_classes]),\n",
    "            )\n",
    "            root.left = self._build_id3(\n",
    "                best_left_subset,\n",
    "                depth=depth + 1,\n",
    "                orig_classes=orig_classes,\n",
    "                attribute_labels=attribute_labels,\n",
    "                class_labels=class_labels,\n",
    "            )\n",
    "            root.right = self._build_id3(\n",
    "                best_right_subset,\n",
    "                depth=depth + 1,\n",
    "                orig_classes=orig_classes,\n",
    "                attribute_labels=attribute_labels,\n",
    "                class_labels=class_labels,\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            root = Node(\n",
    "                depth=depth,\n",
    "                entropy=self._entropy(dataset),\n",
    "                samples=dataset.shape[0],\n",
    "                values=[y.tolist().count(c) for c in orig_classes],\n",
    "                label=np.argmax([y.tolist().count(c) for c in orig_classes]),\n",
    "                label_name=class_labels[\n",
    "                    np.argmax([y.tolist().count(c) for c in orig_classes])\n",
    "                ]\n",
    "                if class_labels is not None\n",
    "                else np.argmax([y.tolist().count(c) for c in orig_classes]),\n",
    "            )\n",
    "\n",
    "        return root\n",
    "\n",
    "    def visualize(self) -> None:\n",
    "        queue = list()\n",
    "        queue.append(self.root)\n",
    "\n",
    "        while queue:\n",
    "            v = queue.pop(0)\n",
    "            print(v)\n",
    "            if v.left is not None:\n",
    "                queue.append(v.left)\n",
    "            if v.left is not None:\n",
    "                queue.append(v.right)\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        attribute_labels: np.ndarray = None,\n",
    "        class_labels: np.ndarray = None,\n",
    "    ) -> None:\n",
    "        if attribute_labels is not None:\n",
    "            if attribute_labels.shape[0] != X.shape[1]:\n",
    "                raise Exception(\"Invalid shape of given attribute labels\")\n",
    "\n",
    "        if class_labels is not None:\n",
    "            if class_labels.shape[0] != np.unique(y).shape[0]:\n",
    "                raise Exception(\"Invalid shape of given class labels\")\n",
    "\n",
    "        if len(y.shape) == 1:\n",
    "            y = np.expand_dims(y, axis=1)\n",
    "\n",
    "        dataset = np.concatenate([X, y], axis=1)\n",
    "        self.root = self._build_id3(\n",
    "            dataset,\n",
    "            depth=0,\n",
    "            orig_classes=np.unique(y),\n",
    "            attribute_labels=attribute_labels,\n",
    "            class_labels=class_labels,\n",
    "        )\n",
    "\n",
    "    def _predict_sample(self, sample: np.ndarray) -> int:\n",
    "        current_node = self.root\n",
    "        current_prediction = current_node.label\n",
    "        while current_node.split_attribute_idx is not None:\n",
    "            if sample[current_node.split_attribute_idx] < current_node.split_threshold:\n",
    "                current_prediction = current_node.left.label\n",
    "                current_node = current_node.left\n",
    "            else:\n",
    "                current_prediction = current_node.right.label\n",
    "                current_node = current_node.right\n",
    "\n",
    "        return current_prediction\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        if len(X.shape) == 1:\n",
    "            X = np.expand_dims(X, axis=0)\n",
    "\n",
    "        if self.root is not None:\n",
    "            return np.array([self._predict_sample(sample) for sample in X])\n",
    "        else:\n",
    "            raise Exception(\"Decision Tree is not trained yet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTree(max_depth=3, min_entropy_diff=0.01, min_node_size=30)\n",
    "tree.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    attribute_labels=data.feature_names,\n",
    "    class_labels=data.target_names,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 0, Split attribute: mean concave points, threshold: 0.05182, entropy: 0.952, samples: 455, values: [169, 286], label: benign\n",
      "Depth: 1, entropy: 0.314, samples: 282, values: [16, 266], label: benign\n",
      "Depth: 1, Split attribute: worst perimeter, threshold: 114.6, entropy: 0.517, samples: 173, values: [153, 20], label: malignant\n",
      "Depth: 2, entropy: 0.994, samples: 44, values: [24, 20], label: malignant\n",
      "Depth: 2, entropy: 0.000, samples: 129, values: [129, 0], label: malignant\n"
     ]
    }
   ],
   "source": [
    "tree.visualize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tree.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87        43\n",
      "           1       0.94      0.89      0.91        71\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.89      0.90      0.89       114\n",
      "weighted avg       0.90      0.89      0.90       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model from Sklearn for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_decision_tree = DecisionTreeClassifier(\n",
    "    criterion=\"entropy\",\n",
    "    max_depth=3,\n",
    "    min_samples_split=30,\n",
    "    random_state=42,\n",
    "    min_samples_leaf=30,\n",
    "    min_impurity_decrease=0.01,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=3,\n",
       "                       min_impurity_decrease=0.01, min_samples_leaf=30,\n",
       "                       min_samples_split=30, random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_decision_tree.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 3.0.0 (20220226.1711)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"680pt\" height=\"433pt\"\n viewBox=\"0.00 0.00 680.00 433.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 429)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-429 676,-429 676,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#aed7f4\" stroke=\"black\" d=\"M479.5,-425C479.5,-425 291.5,-425 291.5,-425 285.5,-425 279.5,-419 279.5,-413 279.5,-413 279.5,-354 279.5,-354 279.5,-348 285.5,-342 291.5,-342 291.5,-342 479.5,-342 479.5,-342 485.5,-342 491.5,-348 491.5,-354 491.5,-354 491.5,-413 491.5,-413 491.5,-419 485.5,-425 479.5,-425\"/>\n<text text-anchor=\"middle\" x=\"385.5\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mean concave points &lt;= 0.051</text>\n<text text-anchor=\"middle\" x=\"385.5\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.952</text>\n<text text-anchor=\"middle\" x=\"385.5\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 455</text>\n<text text-anchor=\"middle\" x=\"385.5\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [169, 286]</text>\n<text text-anchor=\"middle\" x=\"385.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#45a3e7\" stroke=\"black\" d=\"M356,-306C356,-306 229,-306 229,-306 223,-306 217,-300 217,-294 217,-294 217,-235 217,-235 217,-229 223,-223 229,-223 229,-223 356,-223 356,-223 362,-223 368,-229 368,-235 368,-235 368,-294 368,-294 368,-300 362,-306 356,-306\"/>\n<text text-anchor=\"middle\" x=\"292.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">worst area &lt;= 759.45</text>\n<text text-anchor=\"middle\" x=\"292.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.314</text>\n<text text-anchor=\"middle\" x=\"292.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 282</text>\n<text text-anchor=\"middle\" x=\"292.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [16, 266]</text>\n<text text-anchor=\"middle\" x=\"292.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M353.23,-341.91C346.09,-332.92 338.46,-323.32 331.09,-314.05\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"333.67,-311.67 324.71,-306.02 328.19,-316.03 333.67,-311.67\"/>\n<text text-anchor=\"middle\" x=\"321.87\" y=\"-327.16\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#e89153\" stroke=\"black\" d=\"M558.5,-306C558.5,-306 398.5,-306 398.5,-306 392.5,-306 386.5,-300 386.5,-294 386.5,-294 386.5,-235 386.5,-235 386.5,-229 392.5,-223 398.5,-223 398.5,-223 558.5,-223 558.5,-223 564.5,-223 570.5,-229 570.5,-235 570.5,-235 570.5,-294 570.5,-294 570.5,-300 564.5,-306 558.5,-306\"/>\n<text text-anchor=\"middle\" x=\"478.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">worst perimeter &lt;= 114.45</text>\n<text text-anchor=\"middle\" x=\"478.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.517</text>\n<text text-anchor=\"middle\" x=\"478.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 173</text>\n<text text-anchor=\"middle\" x=\"478.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [153, 20]</text>\n<text text-anchor=\"middle\" x=\"478.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\n</g>\n<!-- 0&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>0&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M417.77,-341.91C424.91,-332.92 432.54,-323.32 439.91,-314.05\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"442.81,-316.03 446.29,-306.02 437.33,-311.67 442.81,-316.03\"/>\n<text text-anchor=\"middle\" x=\"449.13\" y=\"-327.16\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#3b9ee5\" stroke=\"black\" d=\"M216.5,-187C216.5,-187 28.5,-187 28.5,-187 22.5,-187 16.5,-181 16.5,-175 16.5,-175 16.5,-116 16.5,-116 16.5,-110 22.5,-104 28.5,-104 28.5,-104 216.5,-104 216.5,-104 222.5,-104 228.5,-110 228.5,-116 228.5,-116 228.5,-175 228.5,-175 228.5,-181 222.5,-187 216.5,-187\"/>\n<text text-anchor=\"middle\" x=\"122.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mean concave points &lt;= 0.027</text>\n<text text-anchor=\"middle\" x=\"122.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.097</text>\n<text text-anchor=\"middle\" x=\"122.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 241</text>\n<text text-anchor=\"middle\" x=\"122.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 238]</text>\n<text text-anchor=\"middle\" x=\"122.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M233.52,-222.91C219.41,-213.2 204.24,-202.76 189.79,-192.81\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"191.6,-189.81 181.38,-187.02 187.63,-195.57 191.6,-189.81\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"#95caf1\" stroke=\"black\" d=\"M350.5,-179.5C350.5,-179.5 258.5,-179.5 258.5,-179.5 252.5,-179.5 246.5,-173.5 246.5,-167.5 246.5,-167.5 246.5,-123.5 246.5,-123.5 246.5,-117.5 252.5,-111.5 258.5,-111.5 258.5,-111.5 350.5,-111.5 350.5,-111.5 356.5,-111.5 362.5,-117.5 362.5,-123.5 362.5,-123.5 362.5,-167.5 362.5,-167.5 362.5,-173.5 356.5,-179.5 350.5,-179.5\"/>\n<text text-anchor=\"middle\" x=\"304.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.901</text>\n<text text-anchor=\"middle\" x=\"304.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 41</text>\n<text text-anchor=\"middle\" x=\"304.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [13, 28]</text>\n<text text-anchor=\"middle\" x=\"304.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\n</g>\n<!-- 1&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>1&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M296.66,-222.91C297.76,-212.2 298.95,-200.62 300.06,-189.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"303.56,-189.97 301.1,-179.67 296.6,-189.26 303.56,-189.97\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M101,-68C101,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,0 12,0 12,0 101,0 101,0 107,0 113,-6 113,-12 113,-12 113,-56 113,-56 113,-62 107,-68 101,-68\"/>\n<text text-anchor=\"middle\" x=\"56.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"56.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 168</text>\n<text text-anchor=\"middle\" x=\"56.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 168]</text>\n<text text-anchor=\"middle\" x=\"56.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M97.92,-103.73C92.65,-94.97 87.06,-85.7 81.76,-76.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"84.73,-75.06 76.57,-68.3 78.74,-78.67 84.73,-75.06\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#41a1e6\" stroke=\"black\" d=\"M235.5,-68C235.5,-68 143.5,-68 143.5,-68 137.5,-68 131.5,-62 131.5,-56 131.5,-56 131.5,-12 131.5,-12 131.5,-6 137.5,0 143.5,0 143.5,0 235.5,0 235.5,0 241.5,0 247.5,-6 247.5,-12 247.5,-12 247.5,-56 247.5,-56 247.5,-62 241.5,-68 235.5,-68\"/>\n<text text-anchor=\"middle\" x=\"189.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.247</text>\n<text text-anchor=\"middle\" x=\"189.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 73</text>\n<text text-anchor=\"middle\" x=\"189.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 70]</text>\n<text text-anchor=\"middle\" x=\"189.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = benign</text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M147.45,-103.73C152.81,-94.97 158.48,-85.7 163.86,-76.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"166.89,-78.66 169.12,-68.3 160.92,-75 166.89,-78.66\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<path fill=\"#fbeade\" stroke=\"black\" d=\"M517,-179.5C517,-179.5 416,-179.5 416,-179.5 410,-179.5 404,-173.5 404,-167.5 404,-167.5 404,-123.5 404,-123.5 404,-117.5 410,-111.5 416,-111.5 416,-111.5 517,-111.5 517,-111.5 523,-111.5 529,-117.5 529,-123.5 529,-123.5 529,-167.5 529,-167.5 529,-173.5 523,-179.5 517,-179.5\"/>\n<text text-anchor=\"middle\" x=\"466.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.994</text>\n<text text-anchor=\"middle\" x=\"466.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 44</text>\n<text text-anchor=\"middle\" x=\"466.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [24, 20]</text>\n<text text-anchor=\"middle\" x=\"466.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>6&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M474.34,-222.91C473.24,-212.2 472.05,-200.62 470.94,-189.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"474.4,-189.26 469.9,-179.67 467.44,-189.97 474.4,-189.26\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M660,-179.5C660,-179.5 559,-179.5 559,-179.5 553,-179.5 547,-173.5 547,-167.5 547,-167.5 547,-123.5 547,-123.5 547,-117.5 553,-111.5 559,-111.5 559,-111.5 660,-111.5 660,-111.5 666,-111.5 672,-117.5 672,-123.5 672,-123.5 672,-167.5 672,-167.5 672,-173.5 666,-179.5 660,-179.5\"/>\n<text text-anchor=\"middle\" x=\"609.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"609.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 129</text>\n<text text-anchor=\"middle\" x=\"609.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [129, 0]</text>\n<text text-anchor=\"middle\" x=\"609.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = malignant</text>\n</g>\n<!-- 6&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>6&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M523.95,-222.91C537.17,-211.1 551.6,-198.22 564.77,-186.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"567.24,-188.94 572.36,-179.67 562.57,-183.72 567.24,-188.94\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.sources.Source at 0x279da08fa30>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = export_graphviz(\n",
    "    sklearn_decision_tree,\n",
    "    out_file=None,\n",
    "    feature_names=data.feature_names,\n",
    "    class_names=data.target_names,\n",
    "    rounded=True,\n",
    "    proportion=False,\n",
    "    filled=True,\n",
    ")\n",
    "graphviz.Source(graph, format=\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_sklearn = sklearn_decision_tree.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87        43\n",
      "           1       0.94      0.89      0.91        71\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.89      0.90      0.89       114\n",
      "weighted avg       0.90      0.89      0.90       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions_sklearn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3387639f90ff78668b9166b82532e0a4254e4114bba40ba72563f9784614f2c3"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
